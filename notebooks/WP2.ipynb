{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f85697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.inforet import download_and_extract, load_split, batched_topk_indices, precision_at_k, predicted_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a236dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 25000 docs | Test (queries): 25000 docs\n"
     ]
    }
   ],
   "source": [
    "download_and_extract()\n",
    "\n",
    "X_train, y_train = load_split(\"train\")\n",
    "X_test, y_test = load_split(\"test\")\n",
    "\n",
    "print(f\"Train: {len(X_train)} docs | Test (queries): {len(X_test)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d1f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6139c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF index on TRAIN\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=50)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5448ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2586  5570  6341 ...  1177 20747  3629]\n",
      " [15341 14828  3518 ...  1170 17333 21044]\n",
      " [21090   125 15619 ...  8322 24278  7710]\n",
      " ...\n",
      " [ 9703 15964  6302 ... 12837 16021 10163]\n",
      " [22054 12922  1909 ...  8581 22278 14232]\n",
      " [14999  2216 15857 ...  7676 15024 18175]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate retrieval-by-sentiment\n",
    "K = 10\n",
    "topk = batched_topk_indices(X_train_tfidf, X_test_tfidf, k = K)\n",
    "\n",
    "print(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b35c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_p_at_k = precision_at_k(topk, y_train, y_test)\n",
    "\n",
    "pos_mask = (y_test == 1)\n",
    "neg_mask = (y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e213c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_at_k_pos = precision_at_k(topk[pos_mask], y_train, y_test[pos_mask])\n",
    "p_at_k_neg = precision_at_k(topk[neg_mask], y_train, y_test[neg_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748af665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision@10 (label match):\n",
      " Overall: 0.5846\n",
      " Pos queries -> Pos retrieved: 0.5808\n",
      " Neg queries -> Neg retrieved: 0.5884\n",
      "\n",
      "Example query:\n",
      " Query label:  pos\n",
      " Query text:  I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. ...\n",
      " Top retrieved labels:  ['pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos', 'neg', 'neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPrecision@{K} (label match):\")\n",
    "print(f\" Overall: {overall_p_at_k:.4f}\")\n",
    "print(f\" Pos queries -> Pos retrieved: {p_at_k_pos:.4f}\")\n",
    "print(f\" Neg queries -> Neg retrieved: {p_at_k_neg:.4f}\")\n",
    "\n",
    "# Optional : show one example query + retrieved labels\n",
    "\n",
    "qi = 0\n",
    "retrieved = topk[qi]\n",
    "print(\"\\nExample query:\")\n",
    "print(\" Query label: \", \"pos\" if y_test[qi] == 1 else \"neg\")\n",
    "print(\" Query text: \", X_test[qi][:200].replace(\"\\n\", \" \"), \"...\")\n",
    "print(\" Top retrieved labels: \", [\"pos\" if y_train[i] == 1 else \"neg\" for i in retrieved])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4afa6",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "To find the score of a review we could use:\n",
    " - a similarity score : how simmilar the new query is to current positive/negative reviews.\n",
    " - predicterd sentiments: a 0 or 1 label based on the majority/weighted average of the top_k neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6e20fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5454545454545454)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = predicted_sentiment(\"\", vectorizer, X_train_tfidf, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48bd2fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements: 1\n"
     ]
    }
   ],
   "source": [
    "debug_query = vectorizer.transform([\"This movie was an absolute masterpiece\"])\n",
    "print(f\"Non-zero elements: {debug_query.nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e06a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m query_vec = vectorizer.transform([\u001b[33m\"\u001b[39m\u001b[33mThis movie was an absolute masterpiece !\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get the indices manually\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m indices = \u001b[43mbatched_topk_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved Indices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindices\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabels of neighbors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train[indices[\u001b[32m0\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\charl\\OneDrive\\Bureau\\A4\\DIA\\Information-retrieval-NLP\\src\\inforet.py:52\u001b[39m, in \u001b[36mbatched_topk_indices\u001b[39m\u001b[34m(doc_matrix, query_matrix, k, batch_size)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03mCompute top-k indices using batching to save memory.\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03mdoc_matrix: (n_docs, n_features) - sparse or dense\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03mquery_matrix: (n_queries, n_features) - sparse or dense\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m n_queries = query_matrix.shape[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m n_docs = \u001b[43mdoc_matrix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     53\u001b[39m k = \u001b[38;5;28mmin\u001b[39m(k, n_docs)\n\u001b[32m     55\u001b[39m all_topk_idx = np.zeros((n_queries, k), dtype=np.int32)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Create a vector for your query\n",
    "query_vec = vectorizer.transform([\"This movie was an absolute masterpiece !\"])\n",
    "\n",
    "# Get the indices manually\n",
    "indices = batched_topk_indices(X_train, query_vec, k=10)\n",
    "\n",
    "print(f\"Retrieved Indices: {indices}\")\n",
    "print(f\"Labels of neighbors: {y_train[indices[0]]}\")\n",
    "\n",
    "# Check the similarity scores\n",
    "# (We manually calc dot product for these specific neighbors to see if they are 0)\n",
    "sims = X_train[indices[0]].dot(query_vec.T).toarray()\n",
    "print(f\"Similarities:\\n{sims}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
